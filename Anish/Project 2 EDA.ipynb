{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_lst = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Bag of Words for Reviews\n",
    "\n",
    "The feature indices in these files start from 0, and the text\n",
    "tokens corresponding to a feature index is found in [imdb.vocab]. So a\n",
    "line with 0:7 in a .feat file means the first word in [imdb.vocab]\n",
    "(the) appears 7 times in that review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_svmlight_file(\"../Data/train/labeledBow.feat\")\n",
    "\n",
    "X_train = X_train.todense()\n",
    "y_train = pd.DataFrame(y_train).rename(columns = {0 :\"Score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 9.,  1.,  4., ...,  0.,  0.,  0.],\n",
       "        [ 7.,  4.,  2., ...,  0.,  0.,  0.],\n",
       "        [ 4.,  4.,  4., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [17.,  6.,  7., ...,  0.,  0.,  0.],\n",
       "        [15.,  8.,  3., ...,  0.,  0.,  0.],\n",
       "        [10.,  2.,  2., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score\n",
       "0    9.0\n",
       "1    7.0\n",
       "2    9.0\n",
       "3   10.0\n",
       "4    8.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Score  Sentiment\n",
       "0        9.0          1\n",
       "1        7.0          1\n",
       "2        9.0          1\n",
       "3       10.0          1\n",
       "4        8.0          1\n",
       "...      ...        ...\n",
       "24995    1.0          0\n",
       "24996    1.0          0\n",
       "24997    4.0          0\n",
       "24998    2.0          0\n",
       "24999    2.0          0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"Sentiment\"] = 0\n",
    "y_train.loc[y_train[\"Score\"] >= 7, (\"Sentiment\")] = 1\n",
    "y_train.loc[y_train[\"Score\"] <= 4, (\"Sentiment\")] = 0\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vocabulary = []\n",
    "f = open(\"../Data/imdb.vocab\", \"r\")\n",
    "for token in f:\n",
    "    Vocabulary.append(token.replace('\\n',''))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Expected Rating Per Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Expected_Vocabulary_Rating = []\n",
    "f = open(\"../Data/imdbEr.txt\", \"r\")\n",
    "for expected_rating in f:\n",
    "    Expected_Vocabulary_Rating.append(float(expected_rating.replace('\\n','')))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_idx = []\n",
    "for word in stopword_lst:\n",
    "    try:\n",
    "        stopwords_idx.append(Vocabulary.index(word)) \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tf_idf(X, max_features=None):\n",
    "    num_terms_in_document = X.sum(axis=1).reshape(X.shape[0],1)\n",
    "\n",
    "    tf = (X / num_terms_in_document)\n",
    "\n",
    "    num_documents = X.shape[0]\n",
    "\n",
    "    num_documents_with_t = np.count_nonzero(X, axis=0) + 1\n",
    "\n",
    "    idf = np.log((num_documents + 1) / num_documents_with_t) + 1\n",
    "\n",
    "    return np.multiply(tf,idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = calc_tf_idf(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = pd.DataFrame(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>89517</th>\n",
       "      <th>89518</th>\n",
       "      <th>89519</th>\n",
       "      <th>89520</th>\n",
       "      <th>89521</th>\n",
       "      <th>89522</th>\n",
       "      <th>89523</th>\n",
       "      <th>89524</th>\n",
       "      <th>89525</th>\n",
       "      <th>89526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065762</td>\n",
       "      <td>0.007493</td>\n",
       "      <td>0.029961</td>\n",
       "      <td>0.030506</td>\n",
       "      <td>0.046244</td>\n",
       "      <td>0.032135</td>\n",
       "      <td>0.016168</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.036578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061917</td>\n",
       "      <td>0.036284</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022139</td>\n",
       "      <td>0.019287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035073</td>\n",
       "      <td>0.035968</td>\n",
       "      <td>0.035953</td>\n",
       "      <td>0.064063</td>\n",
       "      <td>0.018498</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.096957</td>\n",
       "      <td>0.019886</td>\n",
       "      <td>0.019878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030681</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.042907</td>\n",
       "      <td>0.021680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056503</td>\n",
       "      <td>0.040116</td>\n",
       "      <td>0.026732</td>\n",
       "      <td>0.018146</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>0.023893</td>\n",
       "      <td>0.048086</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0.061319</td>\n",
       "      <td>0.027948</td>\n",
       "      <td>0.031428</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>0.014982</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.020948</td>\n",
       "      <td>0.017053</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0.021454</td>\n",
       "      <td>0.044004</td>\n",
       "      <td>0.043985</td>\n",
       "      <td>0.016795</td>\n",
       "      <td>0.016973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035604</td>\n",
       "      <td>0.017990</td>\n",
       "      <td>0.013425</td>\n",
       "      <td>0.017543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.074208</td>\n",
       "      <td>0.026860</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>0.022781</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.098858</td>\n",
       "      <td>0.054070</td>\n",
       "      <td>0.020267</td>\n",
       "      <td>0.041273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043476</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0.073069</td>\n",
       "      <td>0.014987</td>\n",
       "      <td>0.014980</td>\n",
       "      <td>0.007627</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.032135</td>\n",
       "      <td>0.032336</td>\n",
       "      <td>0.024508</td>\n",
       "      <td>0.027433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 89527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6      \\\n",
       "0      0.065762  0.007493  0.029961  0.030506  0.046244  0.032135  0.016168   \n",
       "1      0.061917  0.036284  0.018134  0.018464  0.000000  0.038900  0.009786   \n",
       "2      0.035073  0.035968  0.035953  0.064063  0.018498  0.009640  0.009701   \n",
       "3      0.096957  0.019886  0.019878  0.000000  0.030681  0.021320  0.042907   \n",
       "4      0.056503  0.040116  0.026732  0.018146  0.009169  0.023893  0.048086   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24995  0.061319  0.027948  0.031428  0.026667  0.019763  0.014982  0.007538   \n",
       "24996  0.021454  0.044004  0.043985  0.016795  0.016973  0.000000  0.035604   \n",
       "24997  0.074208  0.026860  0.031322  0.022781  0.004604  0.009599  0.009659   \n",
       "24998  0.098858  0.054070  0.020267  0.041273  0.000000  0.043476  0.014583   \n",
       "24999  0.073069  0.014987  0.014980  0.007627  0.069366  0.032135  0.032336   \n",
       "\n",
       "          7         8         9      ...  89517  89518  89519  89520  89521  \\\n",
       "0      0.016339  0.036578  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "1      0.000000  0.022139  0.019287  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2      0.009803  0.000000  0.009560  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "3      0.021680  0.000000  0.010571  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "4      0.029156  0.000000  0.009477  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "...         ...       ...       ...  ...    ...    ...    ...    ...    ...   \n",
       "24995  0.020948  0.017053  0.014856  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "24996  0.017990  0.013425  0.017543  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "24997  0.009761  0.010926  0.004759  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "24998  0.022105  0.000000  0.014371  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "24999  0.024508  0.027433  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       89522  89523  89524  89525  89526  \n",
       "0        0.0    0.0    0.0    0.0    0.0  \n",
       "1        0.0    0.0    0.0    0.0    0.0  \n",
       "2        0.0    0.0    0.0    0.0    0.0  \n",
       "3        0.0    0.0    0.0    0.0    0.0  \n",
       "4        0.0    0.0    0.0    0.0    0.0  \n",
       "...      ...    ...    ...    ...    ...  \n",
       "24995    0.0    0.0    0.0    0.0    0.0  \n",
       "24996    0.0    0.0    0.0    0.0    0.0  \n",
       "24997    0.0    0.0    0.0    0.0    0.0  \n",
       "24998    0.0    0.0    0.0    0.0    0.0  \n",
       "24999    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[25000 rows x 89527 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf_idf.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1000 = weights.sort_values(ascending = False).head(1000).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_subset = pd.DataFrame(X_train[:,top_1000])\n",
    "X_train_subset_tfidf = tf_idf[top_1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>963</th>\n",
       "      <th>877</th>\n",
       "      <th>1231</th>\n",
       "      <th>1029</th>\n",
       "      <th>1024</th>\n",
       "      <th>1083</th>\n",
       "      <th>956</th>\n",
       "      <th>967</th>\n",
       "      <th>1119</th>\n",
       "      <th>1020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065762</td>\n",
       "      <td>0.029961</td>\n",
       "      <td>0.007493</td>\n",
       "      <td>0.030506</td>\n",
       "      <td>0.046244</td>\n",
       "      <td>0.032135</td>\n",
       "      <td>0.016168</td>\n",
       "      <td>0.036578</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061917</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.036284</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.022139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035073</td>\n",
       "      <td>0.035953</td>\n",
       "      <td>0.035968</td>\n",
       "      <td>0.064063</td>\n",
       "      <td>0.018498</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.096957</td>\n",
       "      <td>0.019878</td>\n",
       "      <td>0.019886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030681</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.042907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021680</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056503</td>\n",
       "      <td>0.026732</td>\n",
       "      <td>0.040116</td>\n",
       "      <td>0.018146</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>0.023893</td>\n",
       "      <td>0.048086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0.061319</td>\n",
       "      <td>0.031428</td>\n",
       "      <td>0.027948</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>0.014982</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.017053</td>\n",
       "      <td>0.020948</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0.021454</td>\n",
       "      <td>0.043985</td>\n",
       "      <td>0.044004</td>\n",
       "      <td>0.016795</td>\n",
       "      <td>0.016973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035604</td>\n",
       "      <td>0.013425</td>\n",
       "      <td>0.017990</td>\n",
       "      <td>0.017543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.074208</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>0.026860</td>\n",
       "      <td>0.022781</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.098858</td>\n",
       "      <td>0.020267</td>\n",
       "      <td>0.054070</td>\n",
       "      <td>0.041273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043476</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>0.014371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0.073069</td>\n",
       "      <td>0.014980</td>\n",
       "      <td>0.014987</td>\n",
       "      <td>0.007627</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.032135</td>\n",
       "      <td>0.032336</td>\n",
       "      <td>0.027433</td>\n",
       "      <td>0.024508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         2         1         3         4         5         6     \\\n",
       "0      0.065762  0.029961  0.007493  0.030506  0.046244  0.032135  0.016168   \n",
       "1      0.061917  0.018134  0.036284  0.018464  0.000000  0.038900  0.009786   \n",
       "2      0.035073  0.035953  0.035968  0.064063  0.018498  0.009640  0.009701   \n",
       "3      0.096957  0.019878  0.019886  0.000000  0.030681  0.021320  0.042907   \n",
       "4      0.056503  0.026732  0.040116  0.018146  0.009169  0.023893  0.048086   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24995  0.061319  0.031428  0.027948  0.026667  0.019763  0.014982  0.007538   \n",
       "24996  0.021454  0.043985  0.044004  0.016795  0.016973  0.000000  0.035604   \n",
       "24997  0.074208  0.031322  0.026860  0.022781  0.004604  0.009599  0.009659   \n",
       "24998  0.098858  0.020267  0.054070  0.041273  0.000000  0.043476  0.014583   \n",
       "24999  0.073069  0.014980  0.014987  0.007627  0.069366  0.032135  0.032336   \n",
       "\n",
       "           8         7         9     ...  963       877   1231  1029  1024  \\\n",
       "0      0.036578  0.016339  0.000000  ...   0.0  0.034249   0.0   0.0   0.0   \n",
       "1      0.022139  0.000000  0.019287  ...   0.0  0.000000   0.0   0.0   0.0   \n",
       "2      0.000000  0.009803  0.009560  ...   0.0  0.000000   0.0   0.0   0.0   \n",
       "3      0.000000  0.021680  0.010571  ...   0.0  0.000000   0.0   0.0   0.0   \n",
       "4      0.000000  0.029156  0.009477  ...   0.0  0.000000   0.0   0.0   0.0   \n",
       "...         ...       ...       ...  ...   ...       ...   ...   ...   ...   \n",
       "24995  0.017053  0.020948  0.014856  ...   0.0  0.000000   0.0   0.0   0.0   \n",
       "24996  0.013425  0.017990  0.017543  ...   0.0  0.000000   0.0   0.0   0.0   \n",
       "24997  0.010926  0.009761  0.004759  ...   0.0  0.000000   0.0   0.0   0.0   \n",
       "24998  0.000000  0.022105  0.014371  ...   0.0  0.000000   0.0   0.0   0.0   \n",
       "24999  0.027433  0.024508  0.000000  ...   0.0  0.000000   0.0   0.0   0.0   \n",
       "\n",
       "       1083  956   967   1119      1020  \n",
       "0       0.0   0.0   0.0   0.0  0.000000  \n",
       "1       0.0   0.0   0.0   0.0  0.000000  \n",
       "2       0.0   0.0   0.0   0.0  0.000000  \n",
       "3       0.0   0.0   0.0   0.0  0.000000  \n",
       "4       0.0   0.0   0.0   0.0  0.000000  \n",
       "...     ...   ...   ...   ...       ...  \n",
       "24995   0.0   0.0   0.0   0.0  0.000000  \n",
       "24996   0.0   0.0   0.0   0.0  0.000000  \n",
       "24997   0.0   0.0   0.0   0.0  0.000000  \n",
       "24998   0.0   0.0   0.0   0.0  0.031924  \n",
       "24999   0.0   0.0   0.0   0.0  0.000000  \n",
       "\n",
       "[25000 rows x 1000 columns]"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_subset_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General ML Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Training Set into Training and Validation \n",
    "def train_test_split(frac, X, y):\n",
    "    X_train = X.sample(frac = frac)\n",
    "    X_test = X.drop(X_train.index, axis = 0)\n",
    "    \n",
    "\n",
    "    y_train = y.loc[X_train.index]\n",
    "    \n",
    "   \n",
    "    y_test = y.loc[X_test.index]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def accuracy(yhat,y):\n",
    "    yhat_copy = yhat.copy()\n",
    "    yhat_copy[yhat >= 0.5] = 1\n",
    "    yhat_copy[yhat < 0.5] = 0\n",
    "    return (yhat_copy == y).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Use linear predictor to model the log-odds\n",
    "\n",
    "### Form\n",
    "\n",
    "\\begin{align}\n",
    "\\log \\frac{P(Y_i = 1)}{1 - P(Y_i = 1)} &= \\beta_0 + \\beta_1x_i \\\\\n",
    "P(Y_i = 1) &= \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1x_i)}}\n",
    "\\end{align}\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "\\begin{align}\n",
    "L(Y, \\hat p) &= -\\log [\\hat p ^{Y}(1 - \\hat p)^{1 - Y}] \\\\\n",
    "&= -Y \\log \\hat p - (1 - Y) \\log (1 -\\hat p)\n",
    "\\end{align}\n",
    "\n",
    "### Estimating Logistic Regression Coefficients\n",
    "\n",
    "WTF $\\beta_j \\leftarrow \\beta_j - \\eta\\frac{\\partial L}{\\partial \\beta_j}$\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial \\beta_j} &= \\frac{\\partial L}{\\partial p}\\frac{\\partial \\hat p}{\\partial \\beta_j} \\\\\n",
    "&=  \\bigg(-\\frac{Y}{\\hat p} + \\frac{1 - Y}{1 - \\hat p}\\bigg)\\big(\\hat p (1 - \\hat p)\\cdot x_j\\big) \\\\\n",
    "&= \\big(\\hat p - Y\\big)x_j\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "\n",
    "    def fit(self, X, y, descent = \"stochastic\"):\n",
    "        X = X.values\n",
    "        intercept_col = np.ones(X_train.shape[0]).reshape(X_train.shape[0],1)\n",
    "        X = np.hstack((intercept_col, X))\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "        if descent == \"stochastic\":\n",
    "            self._b = self._stochastic_gradient_descent(X,\n",
    "                                                        y,\n",
    "                                                        n_iter = 100000,\n",
    "                                                        learning_rate = 0.1,\n",
    "                                                        lossConvergence = .001,\n",
    "                                                        batch_size = 32)\n",
    "        else:\n",
    "             self._b = self._gradient_descent(X,\n",
    "                                             y,\n",
    "                                             n_iter = 10000,\n",
    "                                             learning_rate = 0.1)           \n",
    "        \n",
    "    # Stochastic Gradient Descent Algorithm for Logistic Regression \n",
    "    def _stochastic_gradient_descent(self, X, y, n_iter = 10000, learning_rate = 0.01, lossConvergence = .001, batch_size = 128):\n",
    "        y = y.values.reshape(len(y),1)\n",
    "        betas = np.zeros(X.shape[1]).reshape(X.shape[1],1) + 0.1\n",
    "        for i in range(n_iter):\n",
    "            X_index = np.arange(X.shape[0])\n",
    "            np.random.shuffle(X_index)\n",
    "            batch_index = X_index[:batch_size]\n",
    "\n",
    "            X_batch = X[batch_index,:]\n",
    "            y_batch = y[batch_index,:]\n",
    "\n",
    "            yhat = self._sigmoid(np.dot(X_batch, betas))\n",
    "            gradient = np.dot(X_batch.T,(y_batch - yhat))\n",
    "            if self._loss(yhat, y_batch) < lossConvergence:\n",
    "                break\n",
    "            betas +=  learning_rate * (gradient/X.shape[1])\n",
    "        return betas\n",
    "    \n",
    "   # Gradient Descent Algorithm for Logistic Regression \n",
    "    def _gradient_descent(self, X,y, n_iter = 10000, learning_rate = 0.01, lossConvergence = .001):\n",
    "        y = y.values.reshape(len(y),1)\n",
    "        betas = np.zeros(X.shape[1]).reshape(X.shape[1],1) + 0.1\n",
    "        for i in range(n_iter):\n",
    "            yhat = self._sigmoid(np.dot(X, betas))\n",
    "            gradient = np.dot(X.T,(y - yhat))\n",
    "            if self._loss(yhat, y) < lossConvergence:\n",
    "                break\n",
    "            betas +=  learning_rate * (gradient/X.shape[1])\n",
    "        return X, betas\n",
    "    \n",
    "    def _loss(self, yhat, y):\n",
    "        loss_vals = yhat.copy()\n",
    "        loss_vals[y == 1] = -np.log(yhat[y==1])\n",
    "        loss_vals[y == 0] = -np.log(1 - yhat[y==0])\n",
    "        return(loss_vals.mean())\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = X.values\n",
    "        intercept_col = np.ones(X_train.shape[0]).reshape(X_train.shape[0],1)\n",
    "        X = np.hstack((intercept_col, X))\n",
    "        return self._sigmoid(np.dot(X, self._b))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train_subset_tfidf, y_train[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75468"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = logistic_regression.predict(X_train_subset_tfidf)\n",
    "accuracy(yhat,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDiscriminantAnalysis:\n",
    "\n",
    "    def fit(self, df, y, label = \"Sentiment\"):\n",
    "        self._df = df.copy()\n",
    "        self._label = label\n",
    "        self._df[label] = y\n",
    "        self._classes =  self._df[label].unique()\n",
    "        \n",
    "        self._class_means = self._get_class_means()\n",
    "        self._cov_matrix = df.cov()\n",
    "        \n",
    "        self._w = self._w_calc()\n",
    "        self._c = self._c_calc()\n",
    "    \n",
    "    def _w_calc(self):\n",
    "        cov_inv = np.linalg.inv(self._cov_matrix)\n",
    "        diff_vec = self._class_means[1] - self._class_means[0]\n",
    "        w = np.dot(cov_inv, diff_vec)\n",
    "        return w\n",
    "    \n",
    "    def _c_calc(self):\n",
    "        sum_vec = self._class_means[1] + self._class_means[0]\n",
    "        return np.dot(self._w, 0.5 * (sum_vec))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = X.values\n",
    "        w = self._w\n",
    "        c = self._c\n",
    "        score = np.dot(X, w)\n",
    "        yhat = score.copy()\n",
    "        yhat[score > c] = 1\n",
    "        yhat[score <= c] = 0\n",
    "        return yhat.reshape(len(X),1)\n",
    "            \n",
    "            \n",
    "    def _get_class_means(self):\n",
    "        class_feature_means = pd.DataFrame()\n",
    "\n",
    "        for c, rows in self._df.groupby(self._label):\n",
    "            class_feature_means[c] = rows.mean()\n",
    "\n",
    "        return class_feature_means.drop([self._label], axis = 0)\n",
    "    \n",
    "    def _discrim_func(self, X, k):\n",
    "    \n",
    "        pi_k = len(self._df[self._df[self._label] == k]) #[0]\n",
    "\n",
    "        c_means = self._class_means[k]\n",
    "\n",
    "        cov_inv = np.linalg.inv(self._cov_matrix)\n",
    "\n",
    "        result = X.transpose().dot(cov_inv).dot(c_means)\n",
    "        result = result - (1/2) * c_means.transpose().dot(cov_inv).dot(c_means) \n",
    "        result = result + np.log(pi_k)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train_subset_tfidf, y_train[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(yhat,y):\n",
    "    yhat_copy = yhat.copy()\n",
    "    yhat_copy[yhat >= 0.5] = 1\n",
    "    yhat_copy[yhat < 0.5] = 0\n",
    "    return (yhat_copy == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87164"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = lda.predict(X_train_subset_tfidf)\n",
    "accuracy(yhat, y)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
